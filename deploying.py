# -*- coding: utf-8 -*-
"""Deploying.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19QMDh5GRU14SDAiAA3yM5nleLuKyfKV9
"""
import openai
from pinecone import Pinecone
from dotenv import load_dotenv
import os
import textwrap
import streamlit as st

load_dotenv()
openai_api_key = os.getenv('OPENAI_API_KEY')
pinecone_api_key = os.getenv('PINECONE_API_KEY')
### Establish Pinecone Client and Connection
pc = Pinecone(api_key=pinecone_api_key)
index = pc.Index('llmdata')

### Establish OpenAi Client
openai.api_key = openai_api_key
client = openai.OpenAI()

def get_embedding(text, model):
    text = text.replace("\n", " ")
    embedding_object = client.embeddings.create(
        model=model,
        input=text
    )
    return embedding_object.data[0].embedding

def get_context(query, index, embed_model, k):
  query_embeddings = get_embedding(query, model=embed_model)
  pinecone_response = index.query(vector=query_embeddings, top_k=k, include_metadata=True)
  contexts = [item['metadata']['text'] for item in pinecone_response['matches']]
  return contexts, query

def augmented_query(user_query, embed_model, k=2):
  contexts, query = get_context(user_query, index, embed_model, k=k)
  return "\n\n---\n\n".join(contexts)+"\n\n---\n\n"+query

def ask_gpt(system_prompt,user_prompt, model="chatgpt-4o-latest", temp=0.7):

  temperature_=temp

  completion = client.chat.completions.create(
    model=model,
    temperature=temperature_,
    messages=[
        {
            "role": "system",
            "content": system_prompt
        },
        {
            "role": "user",
            "content": user_prompt
        }
    ]
  )
  lines = (completion.choices[0].message.content).split("\n")
  lists = (textwrap.TextWrapper(width=90, break_long_words=False).wrap(line) for line in lines)
  return "\n".join("\n".join(list) for list in lists)

def Yoda_AI(query):
  embed_model ='text-embedding-ada-002'
  primer = f"""
  You are the statistic Master Yoda. You are a wise and powerful statistician teacher. You provide
  complete and consise answers. If the answer cannot be found in the information provided, you truthfully
  say that you can't say in a manner consistent with the light side of the force.
  """
  llm_model='chatgpt-4o-latest'
  user_prompt=augmented_query(query,embed_model)
  return ask_gpt(primer, user_prompt, model=llm_model)

### Streamlit Interface ###
st.title("Statistician")

# Get user input
user_input = st.text_input("Ask your question:", "")

if st.button("Submit"):
    if user_input:
        response = Yoda_AI(user_input)
        st.write("Response:")
        st.write(response)
    else:
       st.write("Please enter a question or request")